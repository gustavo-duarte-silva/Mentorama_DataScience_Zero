{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"MOD11.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"QYDn7RhIj4-M"},"source":["<br>\n","\n","### Exercício: Regressão Linear:\n","__Parte 1:__\n","\n","1- Usando a função getData(), carregue os dados disponibilizados.\n","\n","2- Separe parte dos dados para o dataset de teste.\n","\n","3- Usando a metodologia de validação cruzada, teste diferentes parâmetros da regLinear - diferentes learning_rates e num_steps - para escolher a melhor combinação de parâmetros.\n","\n","4- Implemente a regressão linear do scikit-learn e compare os resultados obtidos.\n","\n","__Parte 2 (Introdução):__\n","\n","Para cada variável explicativa $X_1, .., X_5$, crie outras variáveis usando o __quadrado__ de cada um delas. Desta forma, o conjunto final será de 10 variáveis, em que:\n","\n","$X_6 = (X_1)^{2}$, $X_7 = (X_2)^{2}$, $X_8 = (X_3)^{2}$, $X_9 = (X_4)^{2}$, $X_{10} = (X_5)^{2}$.\n","\n","Ao treinarmos uma regressão linear com essas 10 variáveis, a predição é da forma:\n","\n","$y_{pred} = \\theta_0 + \\theta_1 \\cdot X_1 + .. + \\theta_5 \\cdot X_5 + \\theta_6 \\cdot (X_1)^{2} + .. + \\theta_{10} \\cdot (X_5)^{2}$\n","\n","Como estamos usando o quadrado das variáveis explicativas, dizemos que temos um __modelo de regressão polinomial de grau 2__. Podemos ter variações deste modelo:\n","\n","-Podemos aumentar o grau: basta mudar a potência que elevamos as variáveis. Por exemplo, podemos incluir o __cubo__ das variáveis e termos um modelo polinomial de ordem 3.\n","\n","-Podemos ter __interações__ entre as variáveis: multiplicações entre as variáveis.\n","\n","Exemplo:\n","\n","$y_{pred} = \\theta_0 + \\theta_1 \\cdot X_1 + .. + \\theta_5 \\cdot X_5 + \\theta_6 \\cdot (X_1)^{2} + .. + \\theta_{10} \\cdot (X_5)^{2} + \\theta_{11} \\cdot (X_1)^{3} + \\theta_{12} \\cdot V1 + \\theta_{13} \\cdot V2$,\n","\n","onde\n","\n","$V_1 = X_1 \\cdot X_2$ e $V_2 = (X_2)^{2} \\cdot X_4$\n","\n","__Parte 2 (Exercício):__\n","\n","1- Estude o link:\n","https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n","\n","em que é discutido como criar modelos polinomiais com o scikit-learn de forma detalhada.\n","\n","2- Repita os passos da primeira parte, mas agora considerando polinômios de graus 2 ou mais.\n","\n","3- Inclua regularização Ridge e Lasso nas análises e teste os resultados para diferentes parâmetros $\\alpha$.\n","\n","<br>\n","\n","### Exercício: Regressão Logística:\n","\n","__Parte 1:__\n","\n","Crie uma classe regLogistica para treinar o modelo de regressão logística. Essa classe deve ser usada para problemas de classificação binária, cuja variável target assume os valores: 0 (classe negativa) e 1 (classe positiva).\n","\n","O método construtor dessa classe deve possuir 3 parâmetros: learning_rate, num_steps e limiar.\n","\n","Os outros médotos devem ser:\n","\n","    - médoto fit: para treinar o modelo - usando gradient descent\n","    \n","    - médoto predict_proba: para retornar a probabilidade da classe 1\n","    \n","    - médoto predict: retornar a classe predita: 0 ou 1 - dependente do limiar\n","    \n","__Parte 2:__\n","\n","Usando a função getData2(), carregue o dataset disponibilizado.\n","\n","Use a regLogistica, classe criada na parte 1 do exercício, para treinar modelos nestes dados. Use validação cruzada para seleção dos parâmetros. Considere diferentes métricas de classificação e justifique as escolhas."]},{"cell_type":"markdown","metadata":{"id":"E4alk21_oBBs"},"source":["# EXE 1.1 - REGRESSÃO LINEAR"]},{"cell_type":"code","metadata":{"id":"mCxWFblPj4-U","executionInfo":{"status":"ok","timestamp":1637611058747,"user_tz":240,"elapsed":389,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import make_friedman1, make_classification"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"WEcPYDFYRWH6","executionInfo":{"status":"ok","timestamp":1637611060253,"user_tz":240,"elapsed":6,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["from sklearn.model_selection import train_test_split"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"QVHBijpoV2FE","executionInfo":{"status":"ok","timestamp":1637611061857,"user_tz":240,"elapsed":4,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["from sklearn.metrics import mean_squared_error"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yr3JEDh9j4-W","executionInfo":{"status":"ok","timestamp":1637611063169,"user_tz":240,"elapsed":4,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["#função para acessar os dados do exercício 1\n","\n","def getData():\n","    X, y = make_friedman1(n_samples = 10000, n_features = 5, noise = 5.0, random_state = 0)\n","    return X, y"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbc2mD_8PdWj","executionInfo":{"status":"ok","timestamp":1637611068337,"user_tz":240,"elapsed":379,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}},"outputId":"9f8eec50-4dab-406b-823d-1c0a43533818"},"source":["X, y = getData()\n","X.shape, y.shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((10000, 5), (10000,))"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"o3QGEeZ9P2vy","executionInfo":{"status":"ok","timestamp":1637611070093,"user_tz":240,"elapsed":4,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["x1_treino, x1_teste, y1_treino, y1_teste = train_test_split(X, y, test_size=0.30)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Aq1Y5eHRpXV","executionInfo":{"status":"ok","timestamp":1637611080414,"user_tz":240,"elapsed":360,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}},"outputId":"b5930f73-59b7-4c9f-d2e7-0b30be2b3bf4"},"source":["x1_treino.shape, y1_treino.shape"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((7000, 5), (7000,))"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"EMMrg97Qj4-X","executionInfo":{"status":"ok","timestamp":1637611083400,"user_tz":240,"elapsed":382,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["#classe regLinear para exercício\n","\n","class regLinear():\n","    \n","    def __init__(self, learning_rate, num_steps):\n","        self.learning_rate = learning_rate\n","        self.num_steps = num_steps\n","        \n","    def fit(self, X, y):\n","        y = y.reshape(-1,1)\n","        m = X.shape[0] \n","        k = X.shape[1] \n","        theta = np.random.randn(k+1,1) \n","        X_b = np.c_[np.ones((m, 1)), X] \n","        for step in range(self.num_steps):\n","            gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n","            theta = theta - self.learning_rate * gradients\n","        self.theta_final = theta\n","        print(\"modelo treinado.\")\n","        \n","    def predict(self, X):\n","        m = X.shape[0]\n","        X_b = np.c_[np.ones((m, 1)), X]\n","        preds = X_b.dot(self.theta_final)\n","        return preds.reshape(-1,)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZejDv2-TOtp","executionInfo":{"status":"ok","timestamp":1637611243229,"user_tz":240,"elapsed":409,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}},"outputId":"3a45a2db-0f4c-44f5-9e45-2ce388fd6cbe"},"source":["lr = [0.030, 0.075, 0.01, 1]\n","nstp = [2, 50, 100, 200]\n","\n","for i in nstp:\n","  for j in lr:\n","    modelo = regLinear(learning_rate = j, num_steps = i)\n","    modelo.fit(x1_treino, y1_treino)\n","\n","    print('Parametros: lr = {} e nsteps = {}'.format(j, i))\n","    print(\"MSE do treino:\", mean_squared_error(y1_treino, modelo.predict(x1_treino)))\n","    print(\"MSE do teste:\", mean_squared_error(y1_teste, modelo.predict(x1_teste)))\n","    print('====='*10)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["modelo treinado.\n","Parametros: lr = 0.03 e nsteps = 2\n","MSE do treino: 153.98580756342463\n","MSE do teste: 155.04418448129186\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 e nsteps = 2\n","MSE do treino: 72.19771925208138\n","MSE do teste: 73.77689755967126\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 e nsteps = 2\n","MSE do treino: 219.57202641540013\n","MSE do teste: 220.0174655671112\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 e nsteps = 2\n","MSE do treino: 39383.40083904776\n","MSE do teste: 39120.84640297989\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 e nsteps = 50\n","MSE do treino: 34.931775630328566\n","MSE do teste: 36.732573595172624\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 e nsteps = 50\n","MSE do treino: 33.26789670718291\n","MSE do teste: 35.28675774526853\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 e nsteps = 50\n","MSE do treino: 37.33221485049931\n","MSE do teste: 39.31260307086655\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 e nsteps = 50\n","MSE do treino: 8.38074101424109e+57\n","MSE do teste: 8.324195226048476e+57\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 e nsteps = 100\n","MSE do treino: 33.62784102895415\n","MSE do teste: 35.68272398065478\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 e nsteps = 100\n","MSE do treino: 31.347066171051335\n","MSE do teste: 33.193394767604175\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 e nsteps = 100\n","MSE do treino: 35.07024446596473\n","MSE do teste: 37.111593415458984\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 e nsteps = 100\n","MSE do treino: 1.649240267177309e+113\n","MSE do teste: 1.6381126603621042e+113\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 e nsteps = 200\n","MSE do treino: 32.022572774608406\n","MSE do teste: 34.06843180254594\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 e nsteps = 200\n","MSE do treino: 30.701777747539545\n","MSE do teste: 32.55899939777354\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 e nsteps = 200\n","MSE do treino: 35.38157501798266\n","MSE do teste: 37.34495148545747\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 e nsteps = 200\n","MSE do treino: 1.2434756855615167e+224\n","MSE do teste: 1.2350858173363867e+224\n","==================================================\n"]}]},{"cell_type":"code","metadata":{"id":"fUYrYc05VhJl","executionInfo":{"status":"ok","timestamp":1637611249357,"user_tz":240,"elapsed":399,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["from sklearn.linear_model import LinearRegression"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"lEZ9t2eTf96D","executionInfo":{"status":"ok","timestamp":1637611259297,"user_tz":240,"elapsed":363,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["modelo_prov = LinearRegression()\n","modelo_prov.fit(x1_treino, y1_treino)\n","ypred = modelo_prov.predict(x1_treino)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YGuAv-H9gWIX","executionInfo":{"status":"ok","timestamp":1637611272692,"user_tz":240,"elapsed":389,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}},"outputId":"dcf34d08-d6a6-4b58-e0d8-b0c216280588"},"source":["print(\"MSE do treino:\", mean_squared_error(y1_treino, modelo_prov.predict(x1_treino)))\n","print(\"MSE do teste:\", mean_squared_error(y1_teste, modelo_prov.predict(x1_teste)))"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE do treino: 30.325995568516145\n","MSE do teste: 31.937287929401336\n"]}]},{"cell_type":"markdown","metadata":{"id":"RzUZcvfkn8lW"},"source":["#EXE 1.2 - REGRESSÃO LINEAR"]},{"cell_type":"code","metadata":{"id":"3bXC5HSzoKCr","executionInfo":{"status":"ok","timestamp":1637611277079,"user_tz":240,"elapsed":367,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["from sklearn.linear_model import Ridge, Lasso"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"vGs_xDRnoNg7","executionInfo":{"status":"ok","timestamp":1637611278643,"user_tz":240,"elapsed":2,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["from sklearn.preprocessing import PolynomialFeatures"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"DR87iR_7TST0","executionInfo":{"status":"ok","timestamp":1637611279927,"user_tz":240,"elapsed":3,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["from sklearn.preprocessing import StandardScaler"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZoIhUVzzdk8","executionInfo":{"status":"ok","timestamp":1637611330198,"user_tz":240,"elapsed":14628,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}},"outputId":"dd7e70c4-cd42-4503-fa2c-2f11cde05439"},"source":["lr = [0.001, 0.030, 0.075, 0.01, 1]\n","nstp = [2, 4, 6, 50, 100, 200]\n","alp = [0, 0.001, 0.01, 0.1, 1]\n","\n","def polyFit(X, y, grau, lr=lr, nstp=nstp, n_alpha=alp):\n","  poly_features = PolynomialFeatures(degree = grau, include_bias = False)\n","  x_poly = poly_features.fit_transform(X)\n","    \n","  for i in nstp:\n","    for j in lr:\n","      for k in n_alpha:\n","        \n","        modelo = regLinear(learning_rate = j, num_steps = i)\n","        m_ridge = Ridge(alpha = k)\n","        m_lasso = Lasso(alpha = k)\n","        modelo.fit(x_poly, y)\n","        m_ridge.fit(x_poly,y)\n","        m_lasso.fit(x_poly,y)\n","\n","        print('Parametros: lr = {} , nsteps = {} e alpha = {}'.format(j, i, k))\n","        print(\"MSE de treino:\", mean_squared_error(y, modelo.predict(x_poly)))\n","        print(\"MSE de treino RIDGE:\", mean_squared_error(y, m_ridge.predict(x_poly)))\n","        print(\"MSE de treino Lasso:\", mean_squared_error(y, m_lasso.predict(x_poly)))\n","        print('====='*10)\n","\n","polyFit(x1_treino,y1_treino,2)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.001 , nsteps = 2 e alpha = 0\n","MSE de treino: 263.3249564782307\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 2 e alpha = 0.001\n","MSE de treino: 312.2259777027068\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 2 e alpha = 0.01\n","MSE de treino: 227.7618816560292\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 2 e alpha = 0.1\n","MSE de treino: 233.4810943499437\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 2 e alpha = 1\n","MSE de treino: 323.09515470950765\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.03 , nsteps = 2 e alpha = 0\n","MSE de treino: 110.49803224184815\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 2 e alpha = 0.001\n","MSE de treino: 130.04744151518335\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 2 e alpha = 0.01\n","MSE de treino: 122.62320898712306\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 2 e alpha = 0.1\n","MSE de treino: 145.1296210815435\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 2 e alpha = 1\n","MSE de treino: 126.76877686872534\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.075 , nsteps = 2 e alpha = 0\n","MSE de treino: 46.59122393216058\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 2 e alpha = 0.001\n","MSE de treino: 43.40429954453894\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 2 e alpha = 0.01\n","MSE de treino: 46.77135847040404\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 2 e alpha = 0.1\n","MSE de treino: 40.84680265313098\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 2 e alpha = 1\n","MSE de treino: 46.84726098082413\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.01 , nsteps = 2 e alpha = 0\n","MSE de treino: 155.41438366373376\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 2 e alpha = 0.001\n","MSE de treino: 166.7859955993304\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 2 e alpha = 0.01\n","MSE de treino: 269.9910596151712\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 2 e alpha = 0.1\n","MSE de treino: 226.76225848445836\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 2 e alpha = 1\n","MSE de treino: 212.51430658993232\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 1 , nsteps = 2 e alpha = 0\n","MSE de treino: 276780.1040834686\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 2 e alpha = 0.001\n","MSE de treino: 205660.06861324425\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 2 e alpha = 0.01\n","MSE de treino: 307713.13441635115\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 2 e alpha = 0.1\n","MSE de treino: 321429.6593643818\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 2 e alpha = 1\n","MSE de treino: 546052.5041625851\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.001 , nsteps = 4 e alpha = 0\n","MSE de treino: 163.05523890860528\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 4 e alpha = 0.001\n","MSE de treino: 230.44300789909838\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 4 e alpha = 0.01\n","MSE de treino: 177.3597301982407\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 4 e alpha = 0.1\n","MSE de treino: 247.13567366645918\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 4 e alpha = 1\n","MSE de treino: 222.5404827882498\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.03 , nsteps = 4 e alpha = 0\n","MSE de treino: 64.265985380071\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 4 e alpha = 0.001\n","MSE de treino: 58.67305612848039\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 4 e alpha = 0.01\n","MSE de treino: 68.29850871142236\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 4 e alpha = 0.1\n","MSE de treino: 69.44375685674872\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 4 e alpha = 1\n","MSE de treino: 75.72464008111437\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.075 , nsteps = 4 e alpha = 0\n","MSE de treino: 35.23129007775127\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 4 e alpha = 0.001\n","MSE de treino: 34.60474193603196\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 4 e alpha = 0.01\n","MSE de treino: 36.946479240694856\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 4 e alpha = 0.1\n","MSE de treino: 33.52712111021731\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 4 e alpha = 1\n","MSE de treino: 34.04379222134106\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.01 , nsteps = 4 e alpha = 0\n","MSE de treino: 128.9174405049687\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 4 e alpha = 0.001\n","MSE de treino: 160.9837422632859\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 4 e alpha = 0.01\n","MSE de treino: 183.7136292384028\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 4 e alpha = 0.1\n","MSE de treino: 139.41754932913818\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 4 e alpha = 1\n","MSE de treino: 170.56409833543037\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 1 , nsteps = 4 e alpha = 0\n","MSE de treino: 491693218.62245566\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 4 e alpha = 0.001\n","MSE de treino: 574139072.9032371\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 4 e alpha = 0.01\n","MSE de treino: 788015629.8162922\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 4 e alpha = 0.1\n","MSE de treino: 557796350.7317525\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 4 e alpha = 1\n","MSE de treino: 516705555.1895301\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.001 , nsteps = 6 e alpha = 0\n","MSE de treino: 261.87348962720426\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 6 e alpha = 0.001\n","MSE de treino: 191.7975343128078\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 6 e alpha = 0.01\n","MSE de treino: 282.0291883527359\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 6 e alpha = 0.1\n","MSE de treino: 266.01036474435415\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 6 e alpha = 1\n","MSE de treino: 273.78214317306623\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.03 , nsteps = 6 e alpha = 0\n","MSE de treino: 51.43415679429776\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 6 e alpha = 0.001\n","MSE de treino: 46.83319738610735\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 6 e alpha = 0.01\n","MSE de treino: 48.431161020184746\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 6 e alpha = 0.1\n","MSE de treino: 45.16175776099262\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 6 e alpha = 1\n","MSE de treino: 46.14251526481483\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.075 , nsteps = 6 e alpha = 0\n","MSE de treino: 37.88156606596416\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 6 e alpha = 0.001\n","MSE de treino: 35.232536155789724\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 6 e alpha = 0.01\n","MSE de treino: 34.61594925514888\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 6 e alpha = 0.1\n","MSE de treino: 35.07525042919895\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 6 e alpha = 1\n","MSE de treino: 34.72610786835058\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.01 , nsteps = 6 e alpha = 0\n","MSE de treino: 123.22107857138391\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 6 e alpha = 0.001\n","MSE de treino: 146.84811568383876\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 6 e alpha = 0.01\n","MSE de treino: 171.0575920121605\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 6 e alpha = 0.1\n","MSE de treino: 141.84027079753872\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 6 e alpha = 1\n","MSE de treino: 97.07588251809632\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 1 , nsteps = 6 e alpha = 0\n","MSE de treino: 914710696293.3412\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 6 e alpha = 0.001\n","MSE de treino: 535102769241.8063\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 6 e alpha = 0.01\n","MSE de treino: 666625473183.4196\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 6 e alpha = 0.1\n","MSE de treino: 844288619818.9738\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 6 e alpha = 1\n","MSE de treino: 1028557991734.5922\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.001 , nsteps = 50 e alpha = 0\n","MSE de treino: 186.11535311686507\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 50 e alpha = 0.001\n","MSE de treino: 159.92738913623216\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 50 e alpha = 0.01\n","MSE de treino: 144.46285932334794\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 50 e alpha = 0.1\n","MSE de treino: 126.76703896779058\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 50 e alpha = 1\n","MSE de treino: 165.86820897961726\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.03 , nsteps = 50 e alpha = 0\n","MSE de treino: 31.436944518305044\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 50 e alpha = 0.001\n","MSE de treino: 32.038086983354894\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 50 e alpha = 0.01\n","MSE de treino: 32.294410495316136\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 50 e alpha = 0.1\n","MSE de treino: 32.195091993832676\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 50 e alpha = 1\n","MSE de treino: 32.559390601661164\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.075 , nsteps = 50 e alpha = 0\n","MSE de treino: 30.855264936775452\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 50 e alpha = 0.001\n","MSE de treino: 31.111006480557272\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 50 e alpha = 0.01\n","MSE de treino: 31.306740896461847\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 50 e alpha = 0.1\n","MSE de treino: 31.300174097020253\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 50 e alpha = 1\n","MSE de treino: 31.002770888928776\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.01 , nsteps = 50 e alpha = 0\n","MSE de treino: 34.375362535760495\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 50 e alpha = 0.001\n","MSE de treino: 37.19773860594992\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 50 e alpha = 0.01\n","MSE de treino: 34.143409584335075\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 50 e alpha = 0.1\n","MSE de treino: 33.632771156865125\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 50 e alpha = 1\n","MSE de treino: 35.345120032186145\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 1 , nsteps = 50 e alpha = 0\n","MSE de treino: 1.647102874567471e+82\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 50 e alpha = 0.001\n","MSE de treino: 9.08810710737048e+81\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 50 e alpha = 0.01\n","MSE de treino: 1.4465525412185238e+82\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 50 e alpha = 0.1\n","MSE de treino: 1.3357326742493242e+82\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 50 e alpha = 1\n","MSE de treino: 1.2863648598812534e+82\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 100 e alpha = 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["MSE de treino: 128.0804661319717\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 100 e alpha = 0.001\n","MSE de treino: 112.59208630870286\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 100 e alpha = 0.01\n","MSE de treino: 88.14590648307575\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 100 e alpha = 0.1\n","MSE de treino: 87.56499866960336\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 100 e alpha = 1\n","MSE de treino: 103.90758451210269\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.03 , nsteps = 100 e alpha = 0\n","MSE de treino: 31.17413630626592\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 100 e alpha = 0.001\n","MSE de treino: 31.654524745384478\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 100 e alpha = 0.01\n","MSE de treino: 31.577802503870892\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 100 e alpha = 0.1\n","MSE de treino: 31.175851830583646\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 100 e alpha = 1\n","MSE de treino: 31.12179173293219\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.075 , nsteps = 100 e alpha = 0\n","MSE de treino: 30.7869719307125\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 100 e alpha = 0.001\n","MSE de treino: 30.721516720162118\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 100 e alpha = 0.01\n","MSE de treino: 30.575635878776367\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 100 e alpha = 0.1\n","MSE de treino: 30.290421769027425\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 100 e alpha = 1\n","MSE de treino: 30.19349418821933\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.01 , nsteps = 100 e alpha = 0\n","MSE de treino: 32.52952622686285\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 100 e alpha = 0.001\n","MSE de treino: 33.54275305390814\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 100 e alpha = 0.01\n","MSE de treino: 31.933189151964775\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 100 e alpha = 0.1\n","MSE de treino: 32.84957804351388\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 100 e alpha = 1\n","MSE de treino: 32.91249276409791\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 1 , nsteps = 100 e alpha = 0\n","MSE de treino: 4.3296042257523185e+161\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 100 e alpha = 0.001\n","MSE de treino: 8.57005566908568e+161\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 100 e alpha = 0.01\n","MSE de treino: 7.621958635457947e+161\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 100 e alpha = 0.1\n","MSE de treino: 7.956798858733513e+161\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 100 e alpha = 1\n","MSE de treino: 1.222608208364796e+162\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.001 , nsteps = 200 e alpha = 0\n","MSE de treino: 44.41105271353278\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 200 e alpha = 0.001\n","MSE de treino: 48.8996062314202\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 200 e alpha = 0.01\n","MSE de treino: 52.82423876787218\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 200 e alpha = 0.1\n","MSE de treino: 45.114993113001745\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.001 , nsteps = 200 e alpha = 1\n","MSE de treino: 49.193893497991574\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.03 , nsteps = 200 e alpha = 0\n","MSE de treino: 30.989713631967604\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 200 e alpha = 0.001\n","MSE de treino: 30.63501468291635\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 200 e alpha = 0.01\n","MSE de treino: 31.10390891810683\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 200 e alpha = 0.1\n","MSE de treino: 30.514154319998244\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.03 , nsteps = 200 e alpha = 1\n","MSE de treino: 31.102116907264406\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.075 , nsteps = 200 e alpha = 0\n","MSE de treino: 30.646141340547832\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 200 e alpha = 0.001\n","MSE de treino: 30.070771532540544\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 200 e alpha = 0.01\n","MSE de treino: 30.049158439223074\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 200 e alpha = 0.1\n","MSE de treino: 30.437133426679495\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.075 , nsteps = 200 e alpha = 1\n","MSE de treino: 30.3563700479819\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 0.01 , nsteps = 200 e alpha = 0\n","MSE de treino: 31.817514924211487\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 200 e alpha = 0.001\n","MSE de treino: 31.640501811786937\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 200 e alpha = 0.01\n","MSE de treino: 31.60426387532079\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 200 e alpha = 0.1\n","MSE de treino: 31.816431679251753\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 0.01 , nsteps = 200 e alpha = 1\n","MSE de treino: 31.73276699036042\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n","modelo treinado.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.214e+04, tolerance: 3.378e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:427: RuntimeWarning: overflow encountered in square\n","  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:427: RuntimeWarning: overflow encountered in square\n","  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:427: RuntimeWarning: overflow encountered in square\n","  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n"]},{"output_type":"stream","name":"stdout","text":["Parametros: lr = 1 , nsteps = 200 e alpha = 0\n","MSE de treino: inf\n","MSE de treino RIDGE: 26.32489674341244\n","MSE de treino Lasso: 26.32489674341244\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 200 e alpha = 0.001\n","MSE de treino: inf\n","MSE de treino RIDGE: 26.32489676131071\n","MSE de treino Lasso: 26.32971067373852\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 200 e alpha = 0.01\n","MSE de treino: inf\n","MSE de treino RIDGE: 26.3248985309744\n","MSE de treino Lasso: 26.576337281128733\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 200 e alpha = 0.1\n","MSE de treino: inf\n","MSE de treino RIDGE: 26.325073259167542\n","MSE de treino Lasso: 30.733289728358713\n","==================================================\n","modelo treinado.\n","Parametros: lr = 1 , nsteps = 200 e alpha = 1\n","MSE de treino: inf\n","MSE de treino RIDGE: 26.340528355467026\n","MSE de treino Lasso: 48.25607045200398\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:427: RuntimeWarning: overflow encountered in square\n","  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:427: RuntimeWarning: overflow encountered in square\n","  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fB96HHdaPtxk","executionInfo":{"status":"ok","timestamp":1637611352615,"user_tz":240,"elapsed":379,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}},"outputId":"a87b10d1-1409-495e-b85a-8c22021ee496"},"source":["poly_features = PolynomialFeatures(degree = 2, include_bias = False)\n","x_poly = poly_features.fit_transform(x1_treino)\n","\n","modelo_prov_poly = LinearRegression()\n","modelo_prov_poly.fit(x_poly, y1_treino)\n","ypred_poly = modelo_prov_poly.predict(x_poly)\n","mean_squared_error(y_true=y1_treino, y_pred = ypred_poly)"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["26.324896743412445"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"IyyAjVUJoYfV"},"source":["# EXE 2.1 - REGRESSÃO LOGISTICA"]},{"cell_type":"code","metadata":{"id":"PU_JpNGJj4-Y","executionInfo":{"status":"ok","timestamp":1637611364451,"user_tz":240,"elapsed":2,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["#função para acessar os dados do exercício 2\n","\n","def getData2():\n","    X, y = make_classification(n_classes=2, n_features=5, n_samples=10000, random_state = 0)\n","    return X, y"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"84QI89Hu_DuZ","executionInfo":{"status":"ok","timestamp":1637611365700,"user_tz":240,"elapsed":4,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["X11, y11 = getData2() "],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"ec74CiMWQ0Gm","executionInfo":{"status":"ok","timestamp":1637611379078,"user_tz":240,"elapsed":374,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["x2_treino, x2_teste, y2_treino, y2_teste = train_test_split(X11, y11, test_size = 0.3)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mx_R4iH2WnJu","executionInfo":{"status":"ok","timestamp":1637611381800,"user_tz":240,"elapsed":495,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}},"outputId":"7dc0ff97-99e2-4965-dabc-8df0183ecead"},"source":["X11.shape, y11.shape"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((10000, 5), (10000,))"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xgpLi1k5WeJ6","executionInfo":{"status":"ok","timestamp":1637611386751,"user_tz":240,"elapsed":380,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}},"outputId":"d326a531-0e10-4087-ba6d-6be341b5583c"},"source":["x2_treino.shape, y2_treino.shape"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((7000, 5), (7000,))"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"CysmKKh1ZF6b","executionInfo":{"status":"ok","timestamp":1637611390121,"user_tz":240,"elapsed":389,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["class regLogistica():\n","  \n","  def __init__(self, learning_rate, num_steps, limiar):\n","    self.learning_rate = learning_rate\n","    self.num_steps = num_steps\n","    self.limiar = limiar\n","  \n","  def fit(self, X, y):\n","    \n","    X_b = np.c_[np.ones(X.shape[0]), X]\n","\n","    theta = np.random.randn(X_b.shape[1],1)\n","\n","    loss = []\n","\n","    for step in range(self.num_steps):\n","      print('passo:',step)\n","\n","      #calculando a probabilidade \n","      yscores = sigmoid(X_b.dot(theta))\n","    \n","      #calculando o gradiente da Log Loss\n","      gradient = X_b.T.dot(yscores - y)\n","    \n","      #atualizando os pesos\n","      theta = theta - self.learning_rate * gradient\n","    \n","      #calculando a Log Loss dentro do passo\n","      logloss_step = logLossCost(ytrue = y, ypred_probs = yscores)\n","      loss.append(logloss_step)\n","      print(\"Log Loss:\", logloss_step)\n","      print('\\n-----------------------------------------------------------\\n')\n","    \n","    self.theta_final = theta\n","    plt.plot(np.arange(0,self.num_steps), loss, 'ro')\n","  \n","  def predict_proba(self, X):\n","    X_b = np.c_[np.ones(X.shape[0]), X]\n","    self.probs = sigmoid(X_b.dot(self.theta_final))\n","    return self.probs \n","    \n","  def predict(self, probs):\n","    self.ypred = np.where(probs > self.limiar, 1, 0)\n","    return self.ypred\n"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"bE0Gx9N88PYt","executionInfo":{"status":"ok","timestamp":1637611397443,"user_tz":240,"elapsed":369,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["def logLossCost(ytrue, ypred_probs):\n","    return (ytrue * np.log(ypred_probs) + (1 - ytrue) * np.log(1 - ypred_probs)).mean() * -1"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"zjwF_OOl8Q0T","executionInfo":{"status":"ok","timestamp":1637611399038,"user_tz":240,"elapsed":4,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["def sigmoid(t):\n","    return 1 / (1 + np.exp(-t))"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ie4x_2xRQfA1","executionInfo":{"status":"ok","timestamp":1637611923564,"user_tz":240,"elapsed":370,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}}},"source":["from sklearn.metrics import roc_auc_score"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"geCpyPE2F6IR","executionInfo":{"status":"ok","timestamp":1637612555673,"user_tz":240,"elapsed":67845,"user":{"displayName":"gustavo duarte","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11905105489282293802"}},"outputId":"3268d4a8-de01-4049-95ba-968b9f8ed43c"},"source":["log_lr = [0.001, 0.005]\n","log_nstp = [4]\n","log_limiar = [0.5, 0.8]\n","lista_metrica = []\n","\n","for i in log_nstp:\n","  for j in log_lr:\n","    for k in log_limiar:\n","      modelo = regLogistica(j,i,k)\n","      modelo.fit(x2_treino, y2_treino)\n","      \n","      prob = modelo.predict_proba(x2_treino)[:,1]\n","      probb = modelo.predict(x2_treino)\n","\n","      pred_treino = np.where(prob > k, 1, 0)\n","      lista_metrica.append(roc_auc_score(y_true = y2_treino, y_score = pred_treino))\n","      \n","      print('Parametros: log_lr = {}, log_nsteps = {} e log_limiar {}'.format(j, i, k))\n","      print(\"Predict_Proba:\", prob)\n","      print(\"Predict:\", modelo.predict(prob))\n","      print(\"Métrica ROC-AUC:\")\n","      print('Médio Treino', np.mean(lista_metrica))\n","      print('====='*10)\n"],"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["passo: 0\n","Log Loss: 1.7255402902282342\n","\n","-----------------------------------------------------------\n","\n","passo: 1\n","Log Loss: 0.208282712345004\n","\n","-----------------------------------------------------------\n","\n","passo: 2\n","Log Loss: 0.013931226234813743\n","\n","-----------------------------------------------------------\n","\n","passo: 3\n","Log Loss: 0.011987610013965313\n","\n","-----------------------------------------------------------\n","\n","Parametros: log_lr = 0.001, log_nsteps = 4 e log_limiar 0.5\n","Predict_Proba: [0.01714451 0.00240614 0.00582184 ... 0.01597631 0.00509276 0.00584914]\n","Predict: [0 0 0 ... 0 0 0]\n","Métrica ROC-AUC:\n","Médio Treino 0.5\n","==================================================\n","passo: 0\n","Log Loss: 0.9955796167257278\n","\n","-----------------------------------------------------------\n","\n","passo: 1\n","Log Loss: 0.04704676341552477\n","\n","-----------------------------------------------------------\n","\n","passo: 2\n","Log Loss: 0.024857134317581\n","\n","-----------------------------------------------------------\n","\n","passo: 3\n","Log Loss: 0.020075044200831033\n","\n","-----------------------------------------------------------\n","\n","Parametros: log_lr = 0.001, log_nsteps = 4 e log_limiar 0.8\n","Predict_Proba: [0.01434603 0.00702295 0.00898947 ... 0.01571144 0.01033428 0.01548555]\n","Predict: [0 0 0 ... 0 0 0]\n","Métrica ROC-AUC:\n","Médio Treino 0.5\n","==================================================\n","passo: 0\n","Log Loss: 1.241195473790395\n","\n","-----------------------------------------------------------\n","\n","passo: 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in multiply\n","  \n"]},{"output_type":"stream","name":"stdout","text":["Log Loss: nan\n","\n","-----------------------------------------------------------\n","\n","passo: 2\n","Log Loss: nan\n","\n","-----------------------------------------------------------\n","\n","passo: 3\n","Log Loss: nan\n","\n","-----------------------------------------------------------\n","\n","Parametros: log_lr = 0.005, log_nsteps = 4 e log_limiar 0.5\n","Predict_Proba: [2.93543191e-07 1.02851552e-19 3.79752580e-06 ... 7.63536822e-07\n"," 1.20866748e-11 5.55050174e-14]\n","Predict: [0 0 0 ... 0 0 0]\n","Métrica ROC-AUC:\n","Médio Treino 0.5000471876179691\n","==================================================\n","passo: 0\n","Log Loss: 1.2899577672757714\n","\n","-----------------------------------------------------------\n","\n","passo: 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in multiply\n","  \n"]},{"output_type":"stream","name":"stdout","text":["Log Loss: nan\n","\n","-----------------------------------------------------------\n","\n","passo: 2\n","Log Loss: nan\n","\n","-----------------------------------------------------------\n","\n","passo: 3\n","Log Loss: nan\n","\n","-----------------------------------------------------------\n","\n","Parametros: log_lr = 0.005, log_nsteps = 4 e log_limiar 0.8\n","Predict_Proba: [1.53091809e-09 9.50010112e-12 1.50586430e-12 ... 2.39655398e-09\n"," 4.09495852e-11 5.08517824e-09]\n","Predict: [0 0 0 ... 0 0 0]\n","Métrica ROC-AUC:\n","Médio Treino 0.5000353907134768\n","==================================================\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"tn98Lns4cPwG"},"source":[""],"execution_count":null,"outputs":[]}]}